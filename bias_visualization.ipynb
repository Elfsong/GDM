{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain = \"age\"\n",
    "model_name = \"01-ai-Yi-1.5-34B-Chat\"\n",
    "ds = load_dataset(\"Elfsong/CrowdEval\", model_name)\n",
    "status = ds[domain]['status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(status)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import crowd_eval, crowd_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YiAgent: 01-ai/Yi-1.5-34B-Chat\n",
      "[+] Loading 01-ai/Yi-1.5-34B-Chat with vLLM...\n",
      "INFO 11-13 12:09:50 config.py:905] Defaulting to use mp for distributed inference\n",
      "INFO 11-13 12:09:50 llm_engine.py:237] Initializing an LLM engine (v0.6.3.post1) with config: model='01-ai/Yi-1.5-34B-Chat', speculative_config=None, tokenizer='01-ai/Yi-1.5-34B-Chat', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, trust_remote_code=True, dtype=torch.bfloat16, max_seq_len=4096, download_dir='/mnt/data/', load_format=LoadFormat.AUTO, tensor_parallel_size=2, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=None, enforce_eager=False, kv_cache_dtype=auto, quantization_param_path=None, device_config=cuda, decoding_config=DecodingConfig(guided_decoding_backend='outlines'), observability_config=ObservabilityConfig(otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=01-ai/Yi-1.5-34B-Chat, num_scheduler_steps=1, chunked_prefill_enabled=False multi_step_stream_outputs=True, enable_prefix_caching=False, use_async_output_proc=True, use_cached_outputs=False, mm_processor_kwargs=None)\n",
      "WARNING 11-13 12:09:51 multiproc_gpu_executor.py:53] Reducing Torch parallelism from 128 threads to 1 to avoid unnecessary CPU contention. Set OMP_NUM_THREADS in the external environment to tune this value as needed.\n",
      "INFO 11-13 12:09:51 custom_cache_manager.py:17] Setting Triton cache manager to: vllm.triton_utils.custom_cache_manager:CustomCacheManager\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m INFO 11-13 12:09:51 multiproc_worker_utils.py:215] Worker ready; awaiting tasks\n",
      "INFO 11-13 12:09:57 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m INFO 11-13 12:09:57 pynccl.py:63] vLLM is using nccl==2.12.7\n",
      "INFO 11-13 12:09:57 utils.py:1008] Found nccl from library libnccl.so.2\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m INFO 11-13 12:09:57 pynccl.py:63] vLLM is using nccl==2.12.7\n",
      "INFO 11-13 12:10:01 custom_all_reduce_utils.py:204] generating GPU P2P access cache in /home/mingzhe/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 11-13 12:10:25 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/mingzhe/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m INFO 11-13 12:10:25 custom_all_reduce_utils.py:242] reading GPU P2P access cache from /home/mingzhe/.cache/vllm/gpu_p2p_access_cache_for_0,1.json\n",
      "INFO 11-13 12:10:26 shm_broadcast.py:241] vLLM message queue communication handle: Handle(connect_ip='127.0.0.1', local_reader_ranks=[1], buffer=<vllm.distributed.device_communicators.shm_broadcast.ShmRingBuffer object at 0x7f7c85a571c0>, local_subscribe_port=39235, remote_subscribe_port=None)\n",
      "INFO 11-13 12:10:26 model_runner.py:1056] Starting to load model 01-ai/Yi-1.5-34B-Chat...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m INFO 11-13 12:10:26 model_runner.py:1056] Starting to load model 01-ai/Yi-1.5-34B-Chat...\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m INFO 11-13 12:10:28 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
      "INFO 11-13 12:10:28 weight_utils.py:243] Using model weights format ['*.safetensors']\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229] Exception in worker VllmWorkerProcess while processing method load_model.\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229] Traceback (most recent call last):\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/executor/multiproc_worker_utils.py\", line 223, in _run_worker_process\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     output = executor(*args, **kwargs)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/worker/worker.py\", line 183, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     self.model_runner.load_model()\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/worker/model_runner.py\", line 1058, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     self.model = get_model(model_config=self.model_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/__init__.py\", line 19, in get_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     return loader.load_model(model_config=model_config,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 402, in load_model\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     model.load_weights(self._get_all_weights(model_config, model))\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/llama.py\", line 582, in load_weights\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     loader.load_weights(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 203, in load_weights\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     autoloaded_weights = list(self._load_module(\"\", self.module, weights))\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 175, in _load_module\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     for child_prefix, child_weights in self._groupby_prefix(weights):\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 104, in _groupby_prefix\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     for prefix, group in itertools.groupby(weights_by_parts,\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py\", line 101, in <genexpr>\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     weights_by_parts = ((weight_name.split(\".\", 1), weight_data)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/llama.py\", line 582, in <genexpr>\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     loader.load_weights(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 377, in _get_all_weights\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     yield from self._get_weights_iterator(primary_weights)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 336, in _get_weights_iterator\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     hf_folder, hf_weights_files, use_safetensors = self._prepare_weights(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py\", line 292, in _prepare_weights\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     hf_folder = download_weights_from_hf(\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/weight_utils.py\", line 246, in download_weights_from_hf\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     with get_lock(model_name_or_path, cache_dir):\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/weight_utils.py\", line 62, in get_lock\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     os.makedirs(os.path.dirname(lock_dir), exist_ok=True)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]   File \"/home/mingzhe/miniconda3/envs/committee/lib/python3.9/os.py\", line 225, in makedirs\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229]     mkdir(name, mode)\n",
      "\u001b[1;36m(VllmWorkerProcess pid=318845)\u001b[0;0m ERROR 11-13 12:10:28 multiproc_worker_utils.py:229] PermissionError: [Errno 13] Permission denied: '/mnt/data'\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/mnt/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m agent_manager \u001b[38;5;241m=\u001b[39m crowd_agent\u001b[38;5;241m.\u001b[39mAgentManager()\n\u001b[0;32m----> 2\u001b[0m agent \u001b[38;5;241m=\u001b[39m \u001b[43magent_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_agent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYiAgent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m01-ai/Yi-1.5-34B-Chat\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m evaluator \u001b[38;5;241m=\u001b[39m crowd_eval\u001b[38;5;241m.\u001b[39mBBQEvaluator(model_name, \u001b[38;5;241m256\u001b[39m)\n\u001b[1;32m      4\u001b[0m evaluator\u001b[38;5;241m.\u001b[39mbootstrap(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/GDM/crowd_agent.py:42\u001b[0m, in \u001b[0;36mAgentManager.get_agent\u001b[0;34m(self, model_type, model_name)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_agent\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_type, model_name):\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m model_type \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_classes:\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43magent_classes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_vllm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     44\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown model type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/GDM/crowd_agent.py:172\u001b[0m, in \u001b[0;36mYiAgent.__init__\u001b[0;34m(self, model_name, enable_vllm)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model_name, enable_vllm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYiAgent: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menable_vllm\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Projects/GDM/crowd_agent.py:56\u001b[0m, in \u001b[0;36mBaseAgent.__init__\u001b[0;34m(self, model_name, enable_vllm)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m enable_vllm:                \n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Loading \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with vLLM...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpipe \u001b[38;5;241m=\u001b[39m \u001b[43mLLM\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_parallel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgpu_memory_utilization\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.92\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdownload_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/mnt/data/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[+] Processing tokenizer data for format enforcement...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjson_parser \u001b[38;5;241m=\u001b[39m JsonSchemaParser(AnswerFormat\u001b[38;5;241m.\u001b[39mmodel_json_schema())\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/entrypoints/llm.py:177\u001b[0m, in \u001b[0;36mLLM.__init__\u001b[0;34m(self, model, tokenizer, tokenizer_mode, skip_tokenizer_init, trust_remote_code, tensor_parallel_size, dtype, quantization, revision, tokenizer_revision, seed, gpu_memory_utilization, swap_space, cpu_offload_gb, enforce_eager, max_context_len_to_capture, max_seq_len_to_capture, disable_custom_all_reduce, disable_async_output_proc, mm_processor_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdisable_log_stats\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    154\u001b[0m engine_args \u001b[38;5;241m=\u001b[39m EngineArgs(\n\u001b[1;32m    155\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    156\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    176\u001b[0m )\n\u001b[0;32m--> 177\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_engine \u001b[38;5;241m=\u001b[39m \u001b[43mLLMEngine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_engine_args\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mUsageContext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLLM_CLASS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest_counter \u001b[38;5;241m=\u001b[39m Counter()\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/engine/llm_engine.py:573\u001b[0m, in \u001b[0;36mLLMEngine.from_engine_args\u001b[0;34m(cls, engine_args, usage_context, stat_loggers)\u001b[0m\n\u001b[1;32m    571\u001b[0m executor_class \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_get_executor_cls(engine_config)\n\u001b[1;32m    572\u001b[0m \u001b[38;5;66;03m# Create the LLM engine.\u001b[39;00m\n\u001b[0;32m--> 573\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mengine_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexecutor_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlog_stats\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mengine_args\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdisable_log_stats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m    \u001b[49m\u001b[43musage_context\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musage_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstat_loggers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstat_loggers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m engine\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/engine/llm_engine.py:334\u001b[0m, in \u001b[0;36mLLMEngine.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, decoding_config, observability_config, prompt_adapter_config, executor_class, log_stats, usage_context, stat_loggers, input_registry, use_cached_outputs)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_registry \u001b[38;5;241m=\u001b[39m input_registry\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_processor \u001b[38;5;241m=\u001b[39m input_registry\u001b[38;5;241m.\u001b[39mcreate_input_processor(\n\u001b[1;32m    332\u001b[0m     model_config)\n\u001b[0;32m--> 334\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_executor \u001b[38;5;241m=\u001b[39m \u001b[43mexecutor_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mspeculative_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspeculative_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprompt_adapter_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt_adapter_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobservability_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mobservability_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39membedding_mode:\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initialize_kv_caches()\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/executor/distributed_gpu_executor.py:26\u001b[0m, in \u001b[0;36mDistributedGPUExecutor.__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Updated by implementations that require additional args to be passed\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# to the _run_workers execute_model call\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mextra_execute_model_run_workers_kwargs: Dict[\u001b[38;5;28mstr\u001b[39m, Any] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m---> 26\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/executor/executor_base.py:47\u001b[0m, in \u001b[0;36mExecutorBase.__init__\u001b[0;34m(self, model_config, cache_config, parallel_config, scheduler_config, device_config, load_config, lora_config, speculative_config, prompt_adapter_config, observability_config)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt_adapter_config \u001b[38;5;241m=\u001b[39m prompt_adapter_config\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservability_config \u001b[38;5;241m=\u001b[39m observability_config\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_executor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/executor/multiproc_gpu_executor.py:111\u001b[0m, in \u001b[0;36mMultiprocessingGPUExecutor._init_executor\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_worker(\n\u001b[1;32m    109\u001b[0m     distributed_init_method\u001b[38;5;241m=\u001b[39mdistributed_init_method)\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_workers(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minit_device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_workers\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mload_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    112\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_concurrent_workers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\n\u001b[1;32m    113\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mmax_parallel_loading_workers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/executor/multiproc_gpu_executor.py:192\u001b[0m, in \u001b[0;36mMultiprocessingGPUExecutor._run_workers\u001b[0;34m(self, method, async_run_tensor_parallel_workers_only, max_concurrent_workers, *args, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m worker_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    187\u001b[0m     worker\u001b[38;5;241m.\u001b[39mexecute_method(method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m worker \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mworkers\n\u001b[1;32m    189\u001b[0m ]\n\u001b[1;32m    191\u001b[0m driver_worker_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdriver_worker, method)\n\u001b[0;32m--> 192\u001b[0m driver_worker_output \u001b[38;5;241m=\u001b[39m \u001b[43mdriver_worker_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;66;03m# Get the results of the workers.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [driver_worker_output\n\u001b[1;32m    196\u001b[0m         ] \u001b[38;5;241m+\u001b[39m [output\u001b[38;5;241m.\u001b[39mget() \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m worker_outputs]\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/worker/worker.py:183\u001b[0m, in \u001b[0;36mWorker.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_model\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/worker/model_runner.py:1058\u001b[0m, in \u001b[0;36mGPUModelRunnerBase.load_model\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1056\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting to load model \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_config\u001b[38;5;241m.\u001b[39mmodel)\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m DeviceMemoryProfiler() \u001b[38;5;28;01mas\u001b[39;00m m:\n\u001b[0;32m-> 1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mget_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1059\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1060\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1061\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1063\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1064\u001b[0m \u001b[43m                           \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1066\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m=\u001b[39m m\u001b[38;5;241m.\u001b[39mconsumed_memory\n\u001b[1;32m   1067\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading model weights took \u001b[39m\u001b[38;5;132;01m%.4f\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1068\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_memory_usage \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m30\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/__init__.py:19\u001b[0m, in \u001b[0;36mget_model\u001b[0;34m(model_config, load_config, device_config, parallel_config, scheduler_config, lora_config, cache_config)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_model\u001b[39m(\u001b[38;5;241m*\u001b[39m, model_config: ModelConfig, load_config: LoadConfig,\n\u001b[1;32m     14\u001b[0m               device_config: DeviceConfig, parallel_config: ParallelConfig,\n\u001b[1;32m     15\u001b[0m               scheduler_config: SchedulerConfig,\n\u001b[1;32m     16\u001b[0m               lora_config: Optional[LoRAConfig],\n\u001b[1;32m     17\u001b[0m               cache_config: CacheConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m nn\u001b[38;5;241m.\u001b[39mModule:\n\u001b[1;32m     18\u001b[0m     loader \u001b[38;5;241m=\u001b[39m get_model_loader(load_config)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlora_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlora_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mparallel_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparallel_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mscheduler_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcache_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py:402\u001b[0m, in \u001b[0;36mDefaultModelLoader.load_model\u001b[0;34m(self, model_config, device_config, lora_config, parallel_config, scheduler_config, cache_config)\u001b[0m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m target_device:\n\u001b[1;32m    398\u001b[0m     model \u001b[38;5;241m=\u001b[39m _initialize_model(model_config, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_config,\n\u001b[1;32m    399\u001b[0m                               lora_config, cache_config,\n\u001b[1;32m    400\u001b[0m                               scheduler_config)\n\u001b[0;32m--> 402\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_all_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[1;32m    405\u001b[0m     quant_method \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquant_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/llama.py:582\u001b[0m, in \u001b[0;36mLlamaForCausalLM.load_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]):\n\u001b[1;32m    577\u001b[0m     loader \u001b[38;5;241m=\u001b[39m AutoWeightsLoader(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    579\u001b[0m         skip_prefixes\u001b[38;5;241m=\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlm_head.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    580\u001b[0m                        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    581\u001b[0m     )\n\u001b[0;32m--> 582\u001b[0m     \u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_remap_mistral\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloaded_weight\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py:203\u001b[0m, in \u001b[0;36mAutoWeightsLoader.load_weights\u001b[0;34m(self, weights, mapper)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mapper \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m     weights \u001b[38;5;241m=\u001b[39m mapper\u001b[38;5;241m.\u001b[39mapply(weights)\n\u001b[0;32m--> 203\u001b[0m autoloaded_weights \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m autoloaded_weights\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py:175\u001b[0m, in \u001b[0;36mAutoWeightsLoader._load_module\u001b[0;34m(self, base_prefix, module, weights)\u001b[0m\n\u001b[1;32m    172\u001b[0m child_modules \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(module\u001b[38;5;241m.\u001b[39mnamed_children())\n\u001b[1;32m    173\u001b[0m child_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(module\u001b[38;5;241m.\u001b[39mnamed_parameters(recurse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m))\n\u001b[0;32m--> 175\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m child_prefix, child_weights \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_groupby_prefix(weights):\n\u001b[1;32m    176\u001b[0m     prefix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_qualname(base_prefix, child_prefix)\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_can_skip(prefix):\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py:104\u001b[0m, in \u001b[0;36mAutoWeightsLoader._groupby_prefix\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_groupby_prefix\u001b[39m(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     99\u001b[0m     weights: Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]]]:\n\u001b[1;32m    101\u001b[0m     weights_by_parts \u001b[38;5;241m=\u001b[39m ((weight_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m), weight_data)\n\u001b[1;32m    102\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m weight_name, weight_data \u001b[38;5;129;01min\u001b[39;00m weights)\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prefix, group \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mgroupby(weights_by_parts,\n\u001b[1;32m    105\u001b[0m                                            key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[1;32m    107\u001b[0m             prefix,\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;66;03m# Because maxsplit=1 in weight_name.split(...),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m parts, weights_data \u001b[38;5;129;01min\u001b[39;00m group),\n\u001b[1;32m    112\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/utils.py:101\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_groupby_prefix\u001b[39m(\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     99\u001b[0m     weights: Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[1;32m    100\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]]]:\n\u001b[0;32m--> 101\u001b[0m     weights_by_parts \u001b[38;5;241m=\u001b[39m ((weight_name\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m), weight_data)\n\u001b[1;32m    102\u001b[0m                         \u001b[38;5;28;01mfor\u001b[39;00m weight_name, weight_data \u001b[38;5;129;01min\u001b[39;00m weights)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m prefix, group \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mgroupby(weights_by_parts,\n\u001b[1;32m    105\u001b[0m                                            key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: x[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m    106\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m (\n\u001b[1;32m    107\u001b[0m             prefix,\n\u001b[1;32m    108\u001b[0m             \u001b[38;5;66;03m# Because maxsplit=1 in weight_name.split(...),\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m              \u001b[38;5;28;01mfor\u001b[39;00m parts, weights_data \u001b[38;5;129;01min\u001b[39;00m group),\n\u001b[1;32m    112\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/models/llama.py:582\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_weights\u001b[39m(\u001b[38;5;28mself\u001b[39m, weights: Iterable[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]]):\n\u001b[1;32m    577\u001b[0m     loader \u001b[38;5;241m=\u001b[39m AutoWeightsLoader(\n\u001b[1;32m    578\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    579\u001b[0m         skip_prefixes\u001b[38;5;241m=\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlm_head.\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    580\u001b[0m                        \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtie_word_embeddings \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m    581\u001b[0m     )\n\u001b[0;32m--> 582\u001b[0m     loader\u001b[38;5;241m.\u001b[39mload_weights(\n\u001b[1;32m    583\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmaybe_remap_mistral(name, loaded_weight)\n\u001b[1;32m    584\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m name, loaded_weight \u001b[38;5;129;01min\u001b[39;00m weights)\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py:377\u001b[0m, in \u001b[0;36mDefaultModelLoader._get_all_weights\u001b[0;34m(self, model_config, model)\u001b[0m\n\u001b[1;32m    365\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_all_weights\u001b[39m(\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    367\u001b[0m     model_config: ModelConfig,\n\u001b[1;32m    368\u001b[0m     model: nn\u001b[38;5;241m.\u001b[39mModule,\n\u001b[1;32m    369\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m    371\u001b[0m     primary_weights \u001b[38;5;241m=\u001b[39m DefaultModelLoader\u001b[38;5;241m.\u001b[39mSource(\n\u001b[1;32m    372\u001b[0m         model_config\u001b[38;5;241m.\u001b[39mmodel,\n\u001b[1;32m    373\u001b[0m         model_config\u001b[38;5;241m.\u001b[39mrevision,\n\u001b[1;32m    374\u001b[0m         prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    375\u001b[0m         fall_back_to_pt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfall_back_to_pt_during_load\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    376\u001b[0m                                 \u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_weights_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprimary_weights\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     secondary_weights \u001b[38;5;241m=\u001b[39m cast(Iterable[DefaultModelLoader\u001b[38;5;241m.\u001b[39mSource],\n\u001b[1;32m    380\u001b[0m                              \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msecondary_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m, ()))\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m source \u001b[38;5;129;01min\u001b[39;00m secondary_weights:\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py:336\u001b[0m, in \u001b[0;36mDefaultModelLoader._get_weights_iterator\u001b[0;34m(self, source)\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_weights_iterator\u001b[39m(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;28mself\u001b[39m, source: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSource\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    334\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Generator[Tuple[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor], \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]:\n\u001b[1;32m    335\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Get an iterator for the model weights based on the load format.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 336\u001b[0m     hf_folder, hf_weights_files, use_safetensors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_weights\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfall_back_to_pt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_config\u001b[38;5;241m.\u001b[39mload_format \u001b[38;5;241m==\u001b[39m LoadFormat\u001b[38;5;241m.\u001b[39mNPCACHE:\n\u001b[1;32m    339\u001b[0m         \u001b[38;5;66;03m# Currently np_cache only support *.bin checkpoints\u001b[39;00m\n\u001b[1;32m    340\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m use_safetensors \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/loader.py:292\u001b[0m, in \u001b[0;36mDefaultModelLoader._prepare_weights\u001b[0;34m(self, model_name_or_path, revision, fall_back_to_pt)\u001b[0m\n\u001b[1;32m    289\u001b[0m     allow_patterns \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m*.pt\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_local:\n\u001b[0;32m--> 292\u001b[0m     hf_folder \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_weights_from_hf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdownload_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_patterns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_config\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mignore_patterns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    300\u001b[0m     hf_folder \u001b[38;5;241m=\u001b[39m model_name_or_path\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/weight_utils.py:246\u001b[0m, in \u001b[0;36mdownload_weights_from_hf\u001b[0;34m(model_name_or_path, cache_dir, allow_patterns, revision, ignore_patterns)\u001b[0m\n\u001b[1;32m    243\u001b[0m logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing model weights format \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, allow_patterns)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;66;03m# Use file lock to prevent multiple processes from\u001b[39;00m\n\u001b[1;32m    245\u001b[0m \u001b[38;5;66;03m# downloading the same model weights at the same time.\u001b[39;00m\n\u001b[0;32m--> 246\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name_or_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    247\u001b[0m     hf_folder \u001b[38;5;241m=\u001b[39m snapshot_download(\n\u001b[1;32m    248\u001b[0m         model_name_or_path,\n\u001b[1;32m    249\u001b[0m         allow_patterns\u001b[38;5;241m=\u001b[39mallow_patterns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    254\u001b[0m         local_files_only\u001b[38;5;241m=\u001b[39mhuggingface_hub\u001b[38;5;241m.\u001b[39mconstants\u001b[38;5;241m.\u001b[39mHF_HUB_OFFLINE,\n\u001b[1;32m    255\u001b[0m     )\n\u001b[1;32m    256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m hf_folder\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/site-packages/vllm/model_executor/model_loader/weight_utils.py:62\u001b[0m, in \u001b[0;36mget_lock\u001b[0;34m(model_name_or_path, cache_dir)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_lock\u001b[39m(model_name_or_path: \u001b[38;5;28mstr\u001b[39m, cache_dir: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     61\u001b[0m     lock_dir \u001b[38;5;241m=\u001b[39m cache_dir \u001b[38;5;129;01mor\u001b[39;00m temp_dir\n\u001b[0;32m---> 62\u001b[0m     \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirname\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlock_dir\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     63\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m model_name_or_path\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     64\u001b[0m     hash_name \u001b[38;5;241m=\u001b[39m hashlib\u001b[38;5;241m.\u001b[39msha256(model_name\u001b[38;5;241m.\u001b[39mencode())\u001b[38;5;241m.\u001b[39mhexdigest()\n",
      "File \u001b[0;32m~/miniconda3/envs/committee/lib/python3.9/os.py:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[0;34m(name, mode, exist_ok)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 225\u001b[0m     \u001b[43mmkdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m    227\u001b[0m     \u001b[38;5;66;03m# Cannot rely on checking for EEXIST, since the operating system\u001b[39;00m\n\u001b[1;32m    228\u001b[0m     \u001b[38;5;66;03m# could give priority to other errors like EACCES or EROFS\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exist_ok \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path\u001b[38;5;241m.\u001b[39misdir(name):\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/mnt/data'"
     ]
    }
   ],
   "source": [
    "agent_manager = crowd_agent.AgentManager()\n",
    "agent = agent_manager.get_agent(\"YiAgent\", \"01-ai/Yi-1.5-34B-Chat\")\n",
    "evaluator = crowd_eval.BBQEvaluator(model_name, 256)\n",
    "evaluator.bootstrap(\"age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "committee",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
